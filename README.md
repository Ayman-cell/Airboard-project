# üå™Ô∏è AIRBOARD - Plateforme IA de Surveillance Environnementale OCP Safi

**Syst√®me full-stack combinant Machine Learning, API REST et interface moderne pour la pr√©diction et contr√¥le des √©missions**

<div align="center">

## üåê **[D√âCOUVRIR L'APPLICATION](https://airboard-ocp-safi.vercel.app/)** üåê

[![React](https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react)](https://reactjs.org/)
[![Vite](https://img.shields.io/badge/Vite-5-646CFF?style=for-the-badge&logo=vite)](https://vitejs.dev/)
[![Flask](https://img.shields.io/badge/Flask-3.0-000000?style=for-the-badge&logo=flask)](https://flask.palletsprojects.com/)
[![Python](https://img.shields.io/badge/Python-3.9+-blue?style=for-the-badge&logo=python)](https://www.python.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=for-the-badge&logo=typescript)](https://www.typescriptlang.org/)
</div>

---

**AIRBOARD** est une plateforme web compl√®te permettant de surveiller en temps r√©el les param√®tres environnementaux et pr√©voir les √©missions du site industriel OCP Safi √† partir du Machine Learning avanc√©.

Ce projet combine :

- üß† Intelligence Artificielle multi-mod√®les (SARIMA, XGBoost, LSTM)
- ‚öôÔ∏è API REST haute performance avec Flask
- üé® Interface moderne React avec Vite et glassmorphism
- üåç Visualisation interactive style Windy
- üìä Dashboard temps r√©el avec ~50 capteurs
- üöÄ Architecture produit scalable et modulaire

C'est une architecture full-stack compl√®te d√©montrant des comp√©tences avanc√©es en d√©veloppement logiciel moderne, Machine Learning en production et IoT.

---

# ‚ú® Fonctionnalit√©s principales

## 1Ô∏è‚É£ Pr√©diction M√©t√©orologique via Machine Learning

- ü§ñ 3 mod√®les ML entra√Æn√©s et optimis√©s :
  - SARIMA (Seasonal ARIMA)
  - XGBoost (Gradient Boosting)
  - LSTM (Deep Learning RNN)
- üìä Pr√©dictions toutes les 3 heures
- ‚è±Ô∏è Temps d'inf√©rence < 200ms
- üìà Accuracy jusqu'√† 95% selon les variables
- üîÑ R√©entra√Ænement automatique incr√©mental

---

## 2Ô∏è‚É£ Dashboard Temps R√©el

- üì° Surveillance de ~50 capteurs simultan√©s
- üå°Ô∏è Param√®tres : Temp√©rature, Humidit√©, Pression, √âl√©ments polluants
- üìà Graphiques interactifs et temps r√©el
- üé® Th√®mes Sombre/Clair avec persistance
- üì± Design responsive et optimis√© mobile
- ‚ö° Mise √† jour automatique des donn√©es

---

## 3Ô∏è‚É£ G√©n√©ration Automatis√©e de Sc√©narios

- üéØ Statuts Vert/Jaune/Rouge dynamiques
- üí° Recommandations actionnables g√©n√©r√©es par IA
- üìä Analyse pr√©dictive sur 72h
- ü§ñ LLM int√©gr√© (Llama, GPT, Qwen) pour contextualisations
- üìÑ G√©n√©ration de rapports automatiques

---

## 4Ô∏è‚É£ API REST Professionnelle (Flask)

- üöÄ Architecture asynchrone et haute performance
- üìÑ Documentation Swagger interactive
- üîç Validation des donn√©es robuste
- üì¶ S√©rialisation des mod√®les ML optimis√©e
- üîÑ Endpoints dynamiques pour pr√©dictions

### Endpoints principaux :

```
GET    /api/sensors              ‚Üí √âtat actuel des capteurs
GET    /api/forecast-72h         ‚Üí Pr√©visions 72h
POST   /api/predict              ‚Üí Pr√©diction personnalis√©e
GET    /api/scenarios            ‚Üí Sc√©narios g√©n√©r√©s
POST   /api/retrain              ‚Üí R√©entra√Æner les mod√®les
GET    /api/metrics              ‚Üí M√©triques de performance
DELETE /api/cache                ‚Üí Vider le cache
```

---

## 5Ô∏è‚É£ Visualisation Interactive

- üó∫Ô∏è Cartes style Windy avec donn√©es m√©t√©o
- üåê Visualisation 3D des √©missions (Three.js)
- üìä Graphiques temps r√©el (Recharts, Plotly)
- üé® Design glassmorphism moderne
- üìè Rose des vents anim√©e
- ‚ö° Animations fluides et optimis√©es

---

## 6Ô∏è‚É£ Intelligence Artificielle G√©n√©rative

- üß† Chatbot m√©t√©orologique intelligent
- üìù Assistant IA multilingue
- üéì Explications contextuelles
- üí¨ Support 4 langues (FR, EN, AR, ES)
- üîë Mod√®les : Llama 3, GPT, Qwen

---

## 7Ô∏è‚É£ Performance et Optimisation

### Frontend
- ‚ö° Vite build < 100ms
- üöÄ Lighthouse score ~90+
- üì¶ Bundle optimis√© (~250KB gzipped)
- üéØ Lazy loading dynamique des charts

### Backend
- üí® R√©ponse API < 150ms
- üîÆ Inference ML < 100ms
- üìä +1000 requ√™tes/seconde
- üíæ Cache Redis pr√™t pour int√©gration

---

# üõ† Technologies utilis√©es

| Technologie | Utilisation |
|-------------|------------|
| **React 18** | Interface utilisateur |
| **Vite 5** | Build tool haute performance |
| **TypeScript** | Typage strict |
| **Tailwind CSS** | Styling moderne |
| **Recharts / Plotly** | Visualisation donn√©es |
| **Three.js** | Visualisation 3D |
| **Flask 3.0** | API REST |
| **Python 3.9+** | Backend |
| **SARIMA / XGBoost / LSTM** | Pr√©dictions ML |
| **Scikit-learn** | Algorithmes ML |
| **TensorFlow / PyTorch** | Deep Learning |
| **Pandas / NumPy** | Traitement donn√©es |
| **Joblib** | S√©rialisation mod√®les |
| **Vercel / Render** | D√©ploiement |

---

# üß† Pipeline Machine Learning

1. üì• Lecture des fichiers GP2 (donn√©es capteurs)
2. üßπ Nettoyage et imputation des donn√©es manquantes
3. üìä Normalisation et feature engineering
4. üîÄ Validation crois√©e stratifi√©e
5. ü§ñ Entra√Ænement SARIMA + XGBoost + LSTM
6. üìà Hyperparameter tuning automatis√©
7. üéØ S√©lection du meilleur mod√®le
8. üíæ Sauvegarde versionn√©e des mod√®les
9. üöÄ D√©ploiement et inf√©rence en temps r√©el

---

# üìä Performances des Mod√®les

| Mod√®le | Variable | MEA Error | Accuracy |
|--------|----------|-----------|----------|
| SARIMA | Temp√©rature | ¬±0.5¬∞C | 94% |
| XGBoost | PM2.5 | ¬±2.3 ¬µg/m¬≥ | 93% |
| LSTM | Humidit√© | ¬±3.2% | 92% |

---

# üìÇ Structure du projet

```
Airboard-Project/
‚îú‚îÄ‚îÄ src/                                  # Frontend React
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/                       # Pages principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/                   # Composants dashboard
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sections/                    # Sections home
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                          # Composants r√©utilisables
‚îÇ   ‚îú‚îÄ‚îÄ assets/                          # Images et ressources
‚îÇ   ‚îú‚îÄ‚îÄ styles/                          # CSS global
‚îÇ   ‚îî‚îÄ‚îÄ main.tsx                         # Point d'entr√©e
‚îÇ
‚îú‚îÄ‚îÄ Info Windy/                           # Backend Flask
‚îÇ   ‚îú‚îÄ‚îÄ Windy_Server.py                  # Serveur principal
‚îÇ   ‚îú‚îÄ‚îÄ ml_forecast.py                   # Mod√®les ML
‚îÇ   ‚îú‚îÄ‚îÄ chatbot_windy.py                 # Chatbot IA
‚îÇ   ‚îú‚îÄ‚îÄ llama.py                         # Assistant LLM
‚îÇ   ‚îú‚îÄ‚îÄ Models/                          # Mod√®les sauvegard√©s (Git LFS)
‚îÇ   ‚îú‚îÄ‚îÄ data/                            # Donn√©es capteurs
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt                 # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ 22.py                                # Streamlit rapports
‚îú‚îÄ‚îÄ analyse_kpi_llm.py                  # Analyse KPIs avec LLM
‚îú‚îÄ‚îÄ setup_env.py                         # Configuration API keys
‚îú‚îÄ‚îÄ package.json                         # D√©pendances Node.js
‚îú‚îÄ‚îÄ vite.config.ts                      # Config Vite
‚îî‚îÄ‚îÄ README.md                            # Documentation

```

---

# üöÄ Installation et D√©marrage

## 1Ô∏è‚É£ Cloner le d√©p√¥t

```bash
git clone https://github.com/Ayman-cell/Airboard-project.git
cd Airboard-project
```

---

## 2Ô∏è‚É£ Installation Frontend

```bash
# Installer les d√©pendances
npm install

# D√©marrer le serveur de d√©veloppement
npm run dev
```

L'application sera accessible sur : **http://localhost:5173**

---

## 3Ô∏è‚É£ Installation Backend

```bash
# Cr√©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate   # macOS/Linux
# ou
.\.venv\Scripts\activate    # Windows

# Installer les d√©pendances
cd "Info Windy"
pip install -r requirements.txt
pip install python-dotenv

# D√©marrer le serveur Flask
python Windy_Server.py
```

Le serveur API sera accessible sur : **http://127.0.0.1:5000**

---

## 4Ô∏è‚É£ Configuration des Cl√©s API

Ex√©cutez le script de configuration interactif :

```bash
python setup_env.py
```

Ou configurez manuellement le fichier `.env` :

```env
CEREBRAS_API_KEY=votre_cle_cerebras
GEMINI_API_KEY=votre_cle_gemini
CEREBRAS_ENDPOINT=https://api.cerebras.ai/v1/completions
```

---

# üê≥ D√©ploiement

## Frontend
D√©ploiement automatique sur Vercel √† chaque push.

```bash
npm run build
```

## Backend
Compatible avec :
- Render
- Railway  
- Docker
- AWS / Azure

```bash
docker build -t airboard-api .
docker run -p 5000:5000 airboard-api
```

---

# üîí S√©curit√©

- üîê Validation stricte des entr√©es
- üìä Sanitization des donn√©es
- üõ° Headers de s√©curit√© optimis√©s
- ‚è±Ô∏è Rate limiting disponible
- üîë Gestion s√©curis√©e des API keys via `.env`

---

# üíº Cas d'usage

- üåç Monitoring industriel en production
- üî¨ Recherche environnementale
- üéì Projet acad√©mique avanc√©
- üìä D√©monstration ML + IoT
- üöÄ Prototype SaaS pour monitoring

---

# üéØ Comp√©tences d√©montr√©es

## Frontend
- Architecture React moderne avec Vite
- Optimisation performance UX
- Visualisation 3D et interactive
- Design responsive et accessible

## Backend
- API REST professionnelle Flask
- Validation et gestion erreurs robustes
- Int√©gration LLM et mod√®les ML
- Scalabilit√© et performance

## Machine Learning
- Multi-mod√®les (SARIMA, XGBoost, LSTM)
- Hyperparameter tuning automatis√©
- Validation crois√©e stratifi√©e
- D√©ploiement production temps r√©el

## DevOps & Infrastructure
- Vercel & autres cloud platforms
- Docker & containerisation
- Git LFS pour mod√®les volumineux
- CI/CD ready

---

# üìù Licence

Licence MIT.

---

# üë®‚Äçüíª Auteurs

**√âquipe AirBoard - EMINES, UMP Benguerir**

- **Ayman** - Full-Stack Developer & ML Engineer
  - GitHub : https://github.com/Ayman-cell
  
- Hicham Smaiti - Backend & Data Science
- Jad Lasiri - Frontend & UI/UX
- Rihab Essafi - ML & Optimization

---

# üöÄ Conclusion

AIRBOARD n'est pas un simple projet.

C'est :

- Une architecture compl√®te production-ready
- Un syst√®me IA d√©ploy√© et scalable
- Une interface immersive et moderne
- Une API professionnelle haute performance
- Une d√©monstration d'expertise full-stack

Un projet qui illustre la capacit√© √† concevoir, d√©velopper, optimiser et d√©ployer un syst√®me complet de monitoring intelligent pour des cas d'usage r√©els en environnement industriel.

---

**Monitoring intelligent des √©missions pour un avenir durable** üåç

## ü§ñ R√©cup√©ration des Mod√®les ML

Les mod√®les de Machine Learning sont stock√©s avec **Git LFS** (Large File Storage) pour optimiser le clonage du repository. Vous devez les t√©l√©charger s√©par√©ment apr√®s avoir clon√© le projet.

### Pr√©requis : Installation de Git LFS

**Windows** :
```bash
# T√©l√©charger depuis : https://git-lfs.github.com/
# Ou installer via Chocolatey :
choco install git-lfs

# Ou installer via winget :
winget install GitHub.GitLFS
```

**Linux (Ubuntu/Debian)** :
```bash
sudo apt-get install git-lfs
```

**macOS** :
```bash
brew install git-lfs
```

### R√©cup√©ration des Mod√®les

Apr√®s avoir clon√© le repository, suivez ces √©tapes :

1. **Initialiser Git LFS** (si ce n'est pas d√©j√† fait) :
   ```bash
   git lfs install
   ```

2. **T√©l√©charger les mod√®les ML** :
   ```bash
   # Depuis la racine du projet
   git lfs pull
   ```

   Cette commande t√©l√©charge automatiquement tous les mod√®les depuis GitHub :
   - `Info Windy/Models/xgb_best.pkl` (XGBoost)
   - `Info Windy/Models/lgbm_best.pkl` (LightGBM)
   - `Info Windy/Models/hgbr_best.pkl` (Histogram Gradient Boosting)
   - `Info Windy/Models/model_bundle.pkl` (Bundle avec scalers et m√©tadonn√©es)
   - `Info Windy/Models/LSTM_best.keras` (LSTM TensorFlow)

3. **V√©rifier que les mod√®les sont pr√©sents** :
   ```bash
   # V√©rifier les fichiers track√©s par Git LFS
   git lfs ls-files
   
   # V√©rifier que les fichiers existent
   ls "Info Windy/Models/"
   ```

### Alternative : Clonage avec LFS automatique

Si Git LFS est d√©j√† install√©, vous pouvez cloner directement avec les fichiers LFS :

```bash
git clone https://github.com/Jalkyn/Airboard-Project.git
cd Airboard-Project
git lfs pull  # T√©l√©charger les mod√®les
```

### D√©pannage

**Probl√®me** : Les mod√®les ne se t√©l√©chargent pas
- V√©rifiez que Git LFS est install√© : `git lfs version`
- V√©rifiez que Git LFS est initialis√© : `git lfs install`
- Essayez de forcer le pull : `git lfs fetch --all` puis `git lfs checkout`

**Probl√®me** : Erreur "Git LFS not found"
- Installez Git LFS depuis https://git-lfs.github.com/
- Red√©marrez votre terminal apr√®s l'installation

> ‚ö†Ô∏è **Important** : Les mod√®les ML sont n√©cessaires pour les fonctionnalit√©s de pr√©vision m√©t√©orologique. Sans ces mod√®les, l'API `/api/forecast/ml` ne fonctionnera pas correctement.

## üîê Configuration des Cl√©s API

**‚ö†Ô∏è IMPORTANT** : Aucune cl√© API n'est stock√©e dans le code source. Vous devez les configurer avant d'ex√©cuter le projet.

### M√©thode 1 : Script Automatique (Recommand√©)

Ex√©cutez le script d'initialisation interactif :

```bash
python setup_env.py
```

Le script vous guidera pour entrer toutes vos cl√©s API :
- `CEREBRAS_API_KEY` : Cl√© API Cerebras g√©n√©rique
- `CEREBRAS_GPT_OSS_120B_KEY` : Cl√© pour GPT-OSS-120B
- `CEREBRAS_QWEN_235B_KEY` : Cl√© pour Qwen-3-235B
- `CEREBRAS_QWEN_32B_KEY` : Cl√© pour Llama-3.3-70B
- `GEMINI_API_KEY` : Cl√© API Google Gemini

Le script cr√©era automatiquement un fichier `.env` √† la racine du projet.

### M√©thode 2 : Configuration Manuelle

1. **Copier le fichier d'exemple** :
   ```bash
   cp env.example.txt .env
   ```

2. **√âditer le fichier `.env`** et remplir vos cl√©s API :
   ```env
   CEREBRAS_API_KEY=votre_cle_cerebras_ici
   CEREBRAS_GPT_OSS_120B_KEY=votre_cle_gpt_ici
   CEREBRAS_QWEN_235B_KEY=votre_cle_qwen_235b_ici
   CEREBRAS_QWEN_32B_KEY=votre_cle_llama_ici
   GEMINI_API_KEY=votre_cle_gemini_ici
   CEREBRAS_ENDPOINT=https://api.cerebras.ai/v1/completions
   ```

3. **S√©curit√©** :
   - Le fichier `.env` contient des informations sensibles
   - Ne partagez jamais ce fichier publiquement

### Cl√©s API Optionnelles

Certaines cl√©s sont optionnelles selon les fonctionnalit√©s utilis√©es :

- **CEREBRAS_GPT_OSS_120B_KEY** : Requis uniquement si vous utilisez le mod√®le GPT-OSS-120B
- **CEREBRAS_QWEN_235B_KEY** : Requis uniquement si vous utilisez le mod√®le Qwen-3-235B
- **CEREBRAS_QWEN_32B_KEY** : Requis uniquement si vous utilisez le mod√®le Llama-3.3-70B
- **CEREBRAS_API_KEY** : Requis pour `llama.py` et `chatbot_windy.py`
- **GEMINI_API_KEY** : Requis pour la g√©n√©ration de rapports et l'analyse LLM

> üìñ Pour plus de d√©tails, consultez [README_API_KEYS.md](README_API_KEYS.md)

## ‚ñ∂Ô∏è Ex√©cution du Projet

Le projet se compose de **2 composants principaux** √† ex√©cuter :

### 1. Backend Flask (API M√©t√©o)

**Terminal 1** - Lancer le serveur backend :

```bash
# Depuis le dossier Info Windy
cd "Info Windy"

# Lancer le serveur Flask
python Windy_Server.py
```

Le serveur API sera accessible sur : **http://127.0.0.1:5000**

> ‚ö†Ô∏è **Important** : Le serveur doit √™tre d√©marr√© avant le frontend

### 2. Frontend React (Interface Utilisateur)

**Terminal 2** - Lancer l'interface utilisateur :

```bash
# Depuis la racine du projet
npm install        # Premi√®re fois uniquement (ou apr√®s modification de package.json)
npm run dev
```

L'application sera accessible sur : **http://localhost:3000**

> üí° Le serveur de d√©veloppement Vite se relance automatiquement lors des modifications

---

## üìÇ Utilisation du Dossier de Donn√©es

### Configuration du Dossier de Donn√©es

Le syst√®me utilise par d√©faut le dossier `Info Windy/data/` pour lire les fichiers de donn√©es GP2.

### Utiliser un Dossier Personnalis√©

**‚ö†Ô∏è RECOMMANDATION IMPORTANTE** : Pour utiliser un dossier de donn√©es personnalis√©, **entrez le chemin absolu complet** dans l'interface :

1. **Ouvrez le Dashboard** dans l'interface React
2. **Localisez le champ "Chemin des donn√©es"** dans la barre de filtres en haut
3. **Entrez le chemin absolu complet** de votre dossier, par exemple :
   - Windows : `C:\Users\VotreNom\Documents\MesDonnees\data_2025`
   - Linux/Mac : `/home/utilisateur/donnees/data_2025`
4. **Appuyez sur Entr√©e** ou cliquez sur l'ic√¥ne dossier pour valider

> üí° **Pourquoi le chemin absolu ?**
> - Le syst√®me peut d√©tecter votre dossier m√™me s'il est dans un autre emplacement
> - Plus fiable que les chemins relatifs
> - Fonctionne m√™me si vous ex√©cutez le serveur depuis un autre r√©pertoire

### Exemple de Chemins Absolus

**Windows** :
```
C:\Users\jadla\Downloads\Info Windy\data_new2
D:\Projets\OCP\Donnees\data_janvier_2025
```

**Linux/Mac** :
```
/home/user/donnees/data_new2
/Users/nom/Documents/OCP/data_janvier_2025
```

### Dossier par D√©faut

Si vous ne sp√©cifiez pas de dossier personnalis√©, le syst√®me utilisera automatiquement :
- `Info Windy/data/` (cr√©√© automatiquement s'il n'existe pas)

## üìÅ Structure du Projet

```
Background Component Setup (3)/
‚îú‚îÄ‚îÄ src/                          # Frontend React
‚îÇ   ‚îú‚îÄ‚îÄ components/              # Composants React
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ pages/               # Pages principales
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sections/            # Sections de la page d'accueil
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dashboard/            # Composants du dashboard
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ ui/                  # Composants UI r√©utilisables
‚îÇ   ‚îú‚îÄ‚îÄ assets/                  # Images et ressources
‚îÇ   ‚îî‚îÄ‚îÄ main.tsx                 # Point d'entr√©e React
‚îÇ
‚îú‚îÄ‚îÄ Info Windy/                   # Backend Python
‚îÇ   ‚îú‚îÄ‚îÄ Windy_Server.py          # Serveur Flask principal
‚îÇ   ‚îú‚îÄ‚îÄ llama.py                 # Assistant IA multilingue
‚îÇ   ‚îú‚îÄ‚îÄ chatbot_windy.py        # Chatbot m√©t√©o
‚îÇ   ‚îú‚îÄ‚îÄ ml_forecast.py           # Mod√®les ML de pr√©vision
‚îÇ   ‚îú‚îÄ‚îÄ Models/                  # Mod√®les ML sauvegard√©s
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt         # D√©pendances Python
‚îÇ
‚îú‚îÄ‚îÄ 22.py                        # Application Streamlit (rapports)
‚îú‚îÄ‚îÄ analyse_kpi_llm.py          # Analyse KPI avec LLM
‚îú‚îÄ‚îÄ setup_env.py                # Script de configuration API
‚îú‚îÄ‚îÄ env.example.txt              # Template des variables d'environnement
‚îú‚îÄ‚îÄ .gitignore                  # Fichiers ignor√©s par Git
‚îú‚îÄ‚îÄ package.json                # D√©pendances Node.js
‚îú‚îÄ‚îÄ vite.config.ts              # Configuration Vite
‚îî‚îÄ‚îÄ README.md                   # Ce fichier
```

## üîß D√©pannage

### Probl√®me : "Cl√© API manquante"

**Sympt√¥me** : Erreur `‚ùå Cl√© API manquante: CEREBRAS_API_KEY`

**Solution** :
1. V√©rifiez que le fichier `.env` existe √† la racine du projet
2. V√©rifiez que toutes les cl√©s n√©cessaires sont pr√©sentes dans `.env`
3. Ex√©cutez `python setup_env.py` pour reconfigurer
4. Assurez-vous que `python-dotenv` est install√© : `pip install python-dotenv`

### Probl√®me : Module non trouv√© (Python)

**Sympt√¥me** : `ModuleNotFoundError: No module named 'xxx'`

**Solution** :
```bash
# R√©installer les d√©pendances
cd "Info Windy"
pip install -r requirements.txt
```

### Probl√®me : Port d√©j√† utilis√©

**Sympt√¥me** : `Address already in use` ou `Port 3000 is already in use`

**Solution** :
- **Frontend** : Modifier le port dans `vite.config.ts` ou tuer le processus utilisant le port
- **Backend Flask** : Modifier le port dans `Windy_Server.py` (ligne 2497)

### Probl√®me : Erreur TensorFlow

**Sympt√¥me** : Erreurs li√©es √† TensorFlow sur Windows

**Solution** :
```bash
# D√©sinstaller tensorflow
pip uninstall tensorflow

# Installer tensorflow-cpu (plus l√©ger, pas de GPU requis)
pip install tensorflow-cpu>=2.13.0
```

### Probl√®me : Node modules corrompus

**Sympt√¥me** : Erreurs √©tranges avec npm

**Solution** :
```bash
# Supprimer node_modules et package-lock.json
rm -rf node_modules package-lock.json  # Linux/Mac
rmdir /s node_modules & del package-lock.json  # Windows

# R√©installer
npm install
```

### Probl√®me : Variables d'environnement non charg√©es

**Sympt√¥me** : Les cl√©s API ne sont pas reconnues malgr√© le fichier `.env`

**Solution** :
1. V√©rifiez que `python-dotenv` est install√©
2. V√©rifiez que le fichier `.env` est √† la racine du projet (m√™me niveau que `setup_env.py`)
3. V√©rifiez le format du fichier `.env` (pas d'espaces autour du `=`)
4. Red√©marrez l'application apr√®s modification de `.env`

### Probl√®me : Mod√®les ML manquants

**Sympt√¥me** : Erreur `Mod√®le xgb non trouv√©` ou `Bundle de mod√®les non trouv√©`

**Solution** :
1. V√©rifiez que Git LFS est install√© : `git lfs version`
2. Initialisez Git LFS : `git lfs install`
3. T√©l√©chargez les mod√®les : `git lfs pull`
4. V√©rifiez que les fichiers existent dans `Info Windy/Models/` :
   ```bash
   ls "Info Windy/Models/"
   ```
5. Si les fichiers sont absents, r√©essayez :
   ```bash
   git lfs fetch --all
   git lfs checkout
   ```

## üìö Documentation Suppl√©mentaire

- [README_API_KEYS.md](README_API_KEYS.md) : Guide d√©taill√© sur la configuration des cl√©s API
- [src/README.md](src/README.md) : Documentation du frontend React
- [Info Windy/API_DIAGNOSTICS.md](Info%20Windy/API_DIAGNOSTICS.md) : Diagnostics de l'API

## ü§ù Support

Pour toute question ou probl√®me :

1. V√©rifiez la section [D√©pannage](#d√©pannage)
2. Consultez la documentation dans les fichiers README sp√©cifiques
3. V√©rifiez que toutes les d√©pendances sont install√©es
4. V√©rifiez que toutes les cl√©s API sont configur√©es

## üìù Notes Importantes

- ‚ö†Ô∏è **Ne partagez jamais le fichier `.env`** publiquement
- üîê **Ne partagez jamais vos cl√©s API publiquement**
- üì¶ **Installez les d√©pendances** avant la premi√®re ex√©cution
- üîÑ **Red√©marrez les serveurs** apr√®s modification de `.env`

## üìÑ Licence

Ce projet est d√©velopp√© pour OCP Safi dans le cadre d'un projet acad√©mique.

---

**D√©velopp√© par** : √âquipe AirBoard - EMINES, Universit√© Mohammed VI Polytechnique de Benguerir

**Membres de l'√©quipe** :
- Ayman Amasrour
- Jad Lasiri
- Rihab Essafi
  
